# Task 6 - KNN Classification

## 📌 Objective
Implement the **K-Nearest Neighbors (KNN)** algorithm for classification problems, experiment with different values of **K**, and visualize decision boundaries.

## 🛠️ Tool--s & Libraries
- Python
- Pandas
- NumPy
- Scikit-learn
- Matplotlib

## 📋 Steps Followed
1. **Choose Dataset** – Used the Iris dataset from scikit-learn.
2. **Preprocessing** –  
   - Train-Test split (80% train, 20% test)  
   - Feature normalization using `StandardScaler`
3. **Model Selection** – Used `KNeighborsClassifier` from scikit-learn.
4. **Experiment with K Values** – Tested `K` from 1 to 10 to find the best accuracy.
5. **Evaluation** – Calculated accuracy and plotted the confusion matrix.
6. **Visualization** – Plotted decision boundaries for the first two features.

## 📊 Results
- **Best K:** 3  *(update if your result is different)*
- **Accuracy:** 96.67% *(update based on your run)*
- **Plots:**
  - **K vs Accuracy**
   
