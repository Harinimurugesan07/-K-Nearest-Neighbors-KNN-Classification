# Task 6 - KNN Classification

## ğŸ“Œ Objective
Implement the **K-Nearest Neighbors (KNN)** algorithm for classification problems, experiment with different values of **K**, and visualize decision boundaries.

## ğŸ› ï¸ Tool--s & Libraries
- Python
- Pandas
- NumPy
- Scikit-learn
- Matplotlib

## ğŸ“‹ Steps Followed
1. **Choose Dataset** â€“ Used the Iris dataset from scikit-learn.
2. **Preprocessing** â€“  
   - Train-Test split (80% train, 20% test)  
   - Feature normalization using `StandardScaler`
3. **Model Selection** â€“ Used `KNeighborsClassifier` from scikit-learn.
4. **Experiment with K Values** â€“ Tested `K` from 1 to 10 to find the best accuracy.
5. **Evaluation** â€“ Calculated accuracy and plotted the confusion matrix.
6. **Visualization** â€“ Plotted decision boundaries for the first two features.

## ğŸ“Š Results
- **Best K:** 3  *(update if your result is different)*
- **Accuracy:** 96.67% *(update based on your run)*
- **Plots:**
  - **K vs Accuracy**
   
